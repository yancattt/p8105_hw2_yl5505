---
title: "p8105_hw2_yl5505"
author: "Yan Li"
date: "2024-10-01"
output: github_document
---

# Problem 0
```{r}
library(tidyverse)
library(readxl)
library(dplyr)
```

# Problem 1
```{r}
nyc_sub = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

nyc_sub
```
-- the dataset has information of Division, Line, Station Name, Station Latitude, and Station Longitude. 
-- the dataset is not tidy,becasue each variable should have its own column. I standardized the column names to a consistent format,selected only relevant columns, and I converted entry variable from character to a logical variable.
-- 1868 rows and 20 columns


## How many distinct stations are there?
```{r}
nyc_sub |> 
  select(station_name, line) |> 
  distinct()
```
-- 465 distinct stations

## How many stations are ADA compliant?
```{r}
nyc_sub |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```
-- 84 are ADA compliant

## What proportion of station entrances / exits without vending allow entrance?

```{r}
no_vending = filter(nyc_sub, vending == "NO")
total_no_vending = nrow(no_vending)
allow_entrance = sum(pull(no_vending, entry))
proportion_no_entry = allow_entrance / total_no_vending

proportion_no_entry
```
-- the proportion is 37.7%. 


## How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?
```{r}
nyc_sub |> 
  mutate(across(starts_with("route"), as.character)) |> 
  pivot_longer(
    cols = starts_with("route"), 
    names_to = "route_num", 
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct() |> 
  count()

```
-- 60 distinct stations serve the A train.

```{r}
nyc_sub |> 
  mutate(across(starts_with("route"), as.character)) |> 
  pivot_longer(
    cols = starts_with("route"), 
    names_to = "route_num", 
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct() |> 
  count() 

```
-- 17 of the stations are ADA compliant. 


# Problem 2
-- import and clean datasets
```{r}
mr_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = "Mr. Trash Wheel", 
                       skip = 1, 
                       na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered)|>
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = as.integer(round(sports_balls)),
         wheel_type = "Mr. Trash Wheel", year = as.character(year))


mr_wheel
```

```{r}
prof_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = "Professor Trash Wheel", 
                       skip = 1, 
                       na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered)|>
  filter(!is.na(dumpster)) |>
  mutate(wheel_type = "Professor Trash Wheel", year = as.character(year))

prof_wheel
```

```{r}
gwynnda_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = "Gwynnda Trash Wheel", 
                       skip = 1, 
                       na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered)|>
  filter(!is.na(dumpster)) |>
  mutate(wheel_type = "Gwynnda Trash Wheel", year = as.character(year))

gwynnda_wheel
```

-- Combine three datasets
```{r}
combined_wheels = bind_rows(mr_wheel, prof_wheel,gwynnda_wheel)

combined_wheels
```
-- The combined dataset has `r nrow(combined_wheels)` observations,and `r ncol(combined_wheels)` variables. Key variables are `r names(combined_wheels)`.

### what was the total weight of trash collected by Professor Trash Wheel?
```{r}
total_weight_prof = combined_wheels |>
  filter(wheel_type == "Professor Trash Wheel") |>
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))

total_weight_prof
```
-- total weight of trash collected by Professor Trash Wheel is 246.74.

### What was the total number of cigarette butts collected by Gwynnda in June of 2022?
```{r}
cigs_gwynnda = combined_wheels |>
  filter(wheel_type == "Gwynnda Trash Wheel", 
         year == "2022", month == "June") |>
  summarize(total_butts = sum(cigarette_butts, na.rm = TRUE))

cigs_gwynnda
```
-- the total number of cigarette butts collected by Gwynnda in June of 2022 is 18120.


# Problem 3
-- import and clean 3 datasets
```{r}
bakers = read_csv("data/bakers.csv")|>
  janitor::clean_names() |>  
  separate(baker_name, into = c("first_name", "last_name"), 
           sep = "\\s", extra = "merge") |>
  mutate(
    series = as.integer(series),  
    baker_age = as.integer(baker_age)
    )


bakes = read_csv("data/bakes.csv")|>
  janitor::clean_names() |>  
  rename(first_name = baker)|> 
  mutate(
    series = as.integer(series),  
    episode = as.integer(episode)
    )

results = read_csv("data/results.csv", skip = 2)|>
  janitor::clean_names() |>
   rename(first_name = baker)|>
  mutate(
    series = as.integer(series),  
    episode = as.integer(episode),  
    result = as.factor(result) 
  )

```
-- I standardized column names and split the baker name into first_name and last_name, I made sure some columns are in correct format, and I adjusted for two initial empty rows in results dataset.

- check for correctness
```{r}
anti_join(bakers, bakes, 
                  by = c("first_name","series"))

anti_join(bakes, results, 
                  by = c("first_name", "episode", "series"))
```
- some bakers listed in the bakers dataset might not have participated in  bakes dataset
- there are baking episodes for "Jo" that have not been accounted for in the results dataset. The correct name is Joanne in results dataset, they entered Jo in bakers dataset, and "Jo" with quotation mark in the bakes dataset.

```{r}
mutate(bakes, first_name = ifelse(first_name == "\"Jo\"", "Jo", first_name), 
         first_name = ifelse(first_name == "Jo", "Joanne", first_name))

mutate(bakers, first_name = ifelse(first_name == "Jo", "Joanne", first_name))
```
-- I corrected the name to Joanne in bakes and bakers dataset. 

### Merge 3 datasets
```{r}
merged_two = left_join(bakers, bakes, by = c("first_name", "series"))

merged_three = left_join(results, merged_two, 
                         by = c("first_name", "series", "episode"))|>
  relocate(series,episode,first_name,last_name, baker_age,hometown,
           technical,result,signature_bake,show_stopper)|>
  arrange(series, episode, first_name, last_name)
  
```
### output the merged dataset
```{r}
write_csv(merged_three, "data/merged_three.csv")
```
- The final merged dataset includes a range of variables from basic demographic information to specific competition details, it is structured around key identifiers such as series, episode, first_name, and last_name, and I also relocated important columns to the front. 

### the star baker or winner of each episode in Seasons 5 through 10
```{r}
final_info = read_csv("data/merged_three.csv")

```

```{r}
winner = final_info |>
  filter(series >= 5 & series <= 10, result %in% c("WINNER", "STAR BAKER")) |>
  select(series, episode, first_name, result)|>
  pivot_wider(
    names_from = episode,
    values_from = first_name,
    names_prefix = "Ep_") |>
    arrange(series)
write_csv(winner, "data/winner.csv")
```
-- Seasons 5 through 9 showed predictable trends, as each winner had been Star Baker at least once. However, Season 10 broke this pattern because David won without ever being Star Baker. 

## Viewers
```{r}
viewers = read_csv("data/viewers.csv", na = c("NA", ".", "")) |>
  janitor::clean_names()
head(viewers, 10)

average_1 = mean(pull(viewers, series_1), na.rm = TRUE)
average_5 = mean(pull(viewers, series_5), na.rm = TRUE)
```
-- the average viewership in Season 1 is `r average_1`, Season 5 is `r average_5`.






