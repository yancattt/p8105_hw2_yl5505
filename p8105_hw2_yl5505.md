p8105_hw2_yl5505
================
Yan Li
2024-10-01

# Problem 0

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
library(dplyr)
```

# Problem 1

``` r
nyc_sub = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

– the dataset has information of Division, Line, Station Name, Station
Latitude, and Station Longitude. – the dataset is not tidy,becasue each
variable should have its own column. I standardized the column names to
a consistent format,selected only relevant columns, and I converted
entry variable from character to a logical variable. – 1868 rows and 20
columns

## How many distinct stations are there?

``` r
nyc_sub |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

– 465 distinct stations

## How many stations are ADA compliant?

``` r
nyc_sub |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # ℹ 74 more rows

– 84 are ADA compliant

## What proportion of station entrances / exits without vending allow entrance?

``` r
no_vending = filter(nyc_sub, vending == "NO")
total_no_vending = nrow(no_vending)
allow_entrance = sum(pull(no_vending, entry))
proportion_no_entry = allow_entrance / total_no_vending

proportion_no_entry
```

    ## [1] 0.3770492

– the proportion is 37.7%.

## How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

``` r
nyc_sub |> 
  mutate(across(starts_with("route"), as.character)) |> 
  pivot_longer(
    cols = starts_with("route"), 
    names_to = "route_num", 
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct() |> 
  count()
```

    ## # A tibble: 1 × 1
    ##       n
    ##   <int>
    ## 1    60

– 60 distinct stations serve the A train.

``` r
nyc_sub |> 
  mutate(across(starts_with("route"), as.character)) |> 
  pivot_longer(
    cols = starts_with("route"), 
    names_to = "route_num", 
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct() |> 
  count() 
```

    ## # A tibble: 1 × 1
    ##       n
    ##   <int>
    ## 1    17

– 17 of the stations are ADA compliant.

# Problem 2

### import and clean datasets

``` r
mr_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = "Mr. Trash Wheel", 
                       skip = 1, 
                       na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered)|>
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = as.integer(round(sports_balls)),
         wheel_type = "Mr. Trash Wheel", year = as.character(year))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
prof_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = "Professor Trash Wheel", 
                       skip = 1, 
                       na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered)|>
  filter(!is.na(dumpster)) |>
  mutate(wheel_type = "Professor Trash Wheel", year = as.character(year))
```

``` r
gwynnda_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = "Gwynnda Trash Wheel", 
                       skip = 1, 
                       na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered)|>
  filter(!is.na(dumpster)) |>
  mutate(wheel_type = "Gwynnda Trash Wheel", year = as.character(year))
```

### Combine three datasets

``` r
combined_wheels = bind_rows(mr_wheel, prof_wheel,gwynnda_wheel)
```

– The combined dataset has 1033 observations,and 15 variables. Key
variables are dumpster, month, year, date, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered,
wheel_type.

### what was the total weight of trash collected by Professor Trash Wheel?

``` r
total_weight_prof = combined_wheels |>
  filter(wheel_type == "Professor Trash Wheel") |>
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))
```

– total weight of trash collected by Professor Trash Wheel is 246.74.

### What was the total number of cigarette butts collected by Gwynnda in June of 2022?

``` r
cigs_gwynnda = combined_wheels |>
  filter(wheel_type == "Gwynnda Trash Wheel", 
         year == "2022", month == "June") |>
  summarize(total_butts = sum(cigarette_butts, na.rm = TRUE))
```

– the total number of cigarette butts collected by Gwynnda in June of
2022 is 18120.

# Problem 3

– import and clean 3 datasets

``` r
bakers = read_csv("data/bakers.csv")|>
  janitor::clean_names() |>  
  separate(baker_name, into = c("first_name", "last_name"), 
           sep = "\\s", extra = "merge") |>
  mutate(
    series = as.integer(series),  
    baker_age = as.integer(baker_age)
    )
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes = read_csv("data/bakes.csv")|>
  janitor::clean_names() |>  
  rename(first_name = baker)|> 
  mutate(
    series = as.integer(series),  
    episode = as.integer(episode)
    )
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results = read_csv("data/results.csv", skip = 2)|>
  janitor::clean_names() |>
   rename(first_name = baker)|>
  mutate(
    series = as.integer(series),  
    episode = as.integer(episode),  
    result = as.factor(result) 
  )
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

– I standardized column names and split the baker name into first_name
and last_name, I made sure some columns are in correct format, and I
adjusted for two initial empty rows in results dataset.

### check for correctness

``` r
anti_join(bakers, bakes, 
                  by = c("first_name","series"))
```

    ## # A tibble: 26 × 6
    ##    first_name last_name       series baker_age baker_occupation         hometown
    ##    <chr>      <chr>            <int>     <int> <chr>                    <chr>   
    ##  1 Alice      Fevronia            10        28 Geography teacher        Essex   
    ##  2 Amelia     LeBruin             10        24 Fashion designer         Halifax 
    ##  3 Antony     Amourdoux            9        30 Banker                   London  
    ##  4 Briony     Williams             9        33 Full-time parent         Bristol 
    ##  5 Dan        Beasley-Harling      9        36 Full-time parent         London  
    ##  6 Dan        Chambers            10        32 Support worker           Rotherh…
    ##  7 David      Atherton            10        36 International health ad… Whitby  
    ##  8 Helena     Garcia              10        40 Online project manager   Leeds   
    ##  9 Henry      Bird                10        20 Student                  Durham  
    ## 10 Imelda     McCarron             9        33 Countryside recreation … County …
    ## # ℹ 16 more rows

``` r
anti_join(bakes, results, 
                  by = c("first_name", "episode", "series"))
```

    ## # A tibble: 8 × 5
    ##   series episode first_name signature_bake                          show_stopper
    ##    <int>   <int> <chr>      <chr>                                   <chr>       
    ## 1      2       1 "\"Jo\""   Chocolate Orange CupcakesOrange and Ca… Chocolate a…
    ## 2      2       2 "\"Jo\""   Caramelised Onion, Gruyere and Thyme Q… Raspberry a…
    ## 3      2       3 "\"Jo\""   Stromboli flavored with Mozzarella, Ha… Unknown     
    ## 4      2       4 "\"Jo\""   Lavender Biscuits                       Blueberry M…
    ## 5      2       5 "\"Jo\""   Salmon and Asparagus Pie                Apple and R…
    ## 6      2       6 "\"Jo\""   Rum and Raisin Baked Cheesecake         Limoncello …
    ## 7      2       7 "\"Jo\""   Raspberry & Strawberry Mousse Cake      Pain Aux Ra…
    ## 8      2       8 "\"Jo\""   Raspberry and Blueberry Mille Feuille   Mini Victor…

- some bakers listed in the bakers dataset might not have participated
  in bakes dataset
- there are baking episodes for “Jo” that have not been accounted for in
  the results dataset. The correct name is Joanne in results dataset,
  they entered Jo in bakers dataset, and “Jo” with quotation mark in the
  bakes dataset.

``` r
mutate(bakes, first_name = ifelse(first_name == "\"Jo\"", "Jo", first_name), 
         first_name = ifelse(first_name == "Jo", "Joanne", first_name))
```

    ## # A tibble: 548 × 5
    ##    series episode first_name signature_bake                         show_stopper
    ##     <int>   <int> <chr>      <chr>                                  <chr>       
    ##  1      1       1 Annetha    "Light Jamaican Black Cakewith Strawb… Red, White …
    ##  2      1       1 David      "Chocolate Orange Cake"                Black Fores…
    ##  3      1       1 Edd        "Caramel Cinnamon and Banana Cake"     N/A         
    ##  4      1       1 Jasminder  "Fresh Mango and Passion Fruit Hummin… N/A         
    ##  5      1       1 Jonathan   "Carrot Cake with Lime and Cream Chee… Three Tiere…
    ##  6      1       1 Lea        "Cranberry and Pistachio Cakewith Ora… Raspberries…
    ##  7      1       1 Louise     "Carrot and Orange Cake"               Never Fail …
    ##  8      1       1 Mark       "Sticky Marmalade Tea Loaf"            Heart-shape…
    ##  9      1       1 Miranda    "Triple Layered Brownie Meringue Cake… Three Tiere…
    ## 10      1       1 Ruth       "Three Tiered Lemon Drizzle Cakewith … Classic Cho…
    ## # ℹ 538 more rows

``` r
mutate(bakers, first_name = ifelse(first_name == "Jo", "Joanne", first_name))
```

    ## # A tibble: 120 × 6
    ##    first_name last_name   series baker_age baker_occupation             hometown
    ##    <chr>      <chr>        <int>     <int> <chr>                        <chr>   
    ##  1 Ali        Imdad            4        25 Charity worker               Saltley…
    ##  2 Alice      Fevronia        10        28 Geography teacher            Essex   
    ##  3 Alvin      Magallanes       6        37 Nurse                        Brackne…
    ##  4 Amelia     LeBruin         10        24 Fashion designer             Halifax 
    ##  5 Andrew     Smyth            7        25 Aerospace engineer           Derby /…
    ##  6 Annetha    Mills            1        30 Midwife                      Essex   
    ##  7 Antony     Amourdoux        9        30 Banker                       London  
    ##  8 Beca       Lyne-Pirkis      4        31 Military Wives' Choir Singer Aldersh…
    ##  9 Ben        Frazer           2        31 Graphic Designer             Northam…
    ## 10 Benjamina  Ebuehi           7        23 Teaching assistant           South L…
    ## # ℹ 110 more rows

– I corrected the name to Joanne in bakes and bakers dataset.

### Merge 3 datasets

``` r
merged_two = left_join(bakers, bakes, by = c("first_name", "series"))

merged_three = left_join(results, merged_two, 
                         by = c("first_name", "series", "episode"))|>
  relocate(series,episode,first_name,last_name, baker_age,hometown,
           technical,result,signature_bake,show_stopper)|>
  arrange(series, episode, first_name, last_name)
```

### output the merged dataset

``` r
write_csv(merged_three, "data/merged_three.csv")
```

- The final merged dataset includes a range of variables from basic
  demographic information to specific competition details, it is
  structured around key identifiers such as series, episode, first_name,
  and last_name, and I also relocated important columns to the front.

### the star baker or winner of each episode in Seasons 5 through 10

``` r
final_info = read_csv("data/merged_three.csv")
```

    ## Rows: 1136 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (7): first_name, last_name, hometown, result, signature_bake, show_stopp...
    ## dbl (4): series, episode, baker_age, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
winner = final_info |>
  filter(series >= 5 & series <= 10, result %in% c("WINNER", "STAR BAKER")) |>
  select(series, episode, first_name, result)|>
  pivot_wider(
    names_from = episode,
    values_from = first_name,
    names_prefix = "Ep_") |>
    arrange(series)
write_csv(winner, "data/winner.csv")
```

– Seasons 5 through 9 showed predictable trends, as each winner had been
Star Baker at least once. However, Season 10 broke this pattern because
David won without ever being Star Baker.

## Viewers

``` r
viewers = read_csv("data/viewers.csv", na = c("NA", ".", "")) |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers, 10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
average_1 = mean(pull(viewers, series_1), na.rm = TRUE)
average_5 = mean(pull(viewers, series_5), na.rm = TRUE)
```

– the average viewership in Season 1 is 2.77, Season 5 is 10.0393.
